{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# クラウドへ（そしてその先へ）\n数値の問題を解決する方法については十分に検討しました。トレーニング部分をクラウドに移行します。（数値の問題ではこれ以上はローカルでの実行は不要ですが、他の問題については、ローカルでサブセットの問題をテストしてからクラウドに移動して全体を処理します）\n\nいくつか設定しましょう。\n\n最初にしなければならないことは、azureml.core パッケージがノートブック環境にインストールされているのを確認することです。Azure Notebooksを使用している場合は、簡単な2ステップのプロセスで確認できます。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Azure Notebooks に依存関係を追加する\n\"Project Settings\" をクリックします。\n\n![Project Setings](https://raw.githubusercontent.com/sethjuarez/pytorchintro/master/images/project_settings.png)\n\n次に、\"Environments\" タブを選択し、\"Python 3.6\" を選択します。最後に、`requirements.txt` を選択します。\n\n![Settings](https://raw.githubusercontent.com/sethjuarez/pytorchintro/master/images/settings.png)\n\nこれらのステップで、実行できるようになるはずです。\n\n**注** もし上記の設定をしても問題が発生する場合は、Notebook でカーネルが Python 3.6 に設定されていることを確認してください。Python 3.6 になっていない場合は、次の操作で設定変更できます: ノートブックのメニューで [Kernel] -[Change Kernel] - [Python 3.6] を選択"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import json\nimport time\nimport azureml\nfrom azureml.core.model import Model\nfrom azureml.core import Workspace, Run, Experiment\nfrom azureml.core.runconfig import RunConfiguration\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\nfrom azureml.train.dnn import PyTorch\nfrom azureml.widgets import RunDetails\nfrom torchvision import datasets, transforms\n\nprint(\"Azure ML SDK Version: \", azureml.core.VERSION)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Azure Machine Learning サービスを設定する\n最初に必要な作業は、Azure Machine Learning サービス ワークスペースを作成することです。その方法についての [ドキュメント](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-get-started#create-a-workspace) があります。コマンドラインタイプに慣れている場合は、Azure CLI を使用してセットアップする方法の [例](https://github.com/sethjuarez/workspacestarter) があります。プロジェクトを設定したら、以下のコードのコメントを外して設定ファイルを書き出し、ワークスペースに適した設定を入力します。設定ファイルが書き出されたら、下記のようにプログラムでワークスペースをロードすることができます。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## config ファイルを設定するには以下のコードを使います\n#subscription_id ='<SUB_ID>'\n#resource_group ='<RESOURCE_GROUP>'\n#workspace_name = '<WORKSPACE>'\n\n#try:\n#    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n#    ws.write_config()\n#    print('Workspace configuration succeeded. You are all set!')\n#except:\n#    print('Workspace not found. TOO MANY ISSUES!!!')\n\n## 上記のコードを一度実行したあとは、保存した config ファイルを利用できます\n#ws = Workspace.from_config()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# クラウドコンピュート\n次に、実験用のコンピュートターゲットを定義する必要があります。これは新規のワークスペースなので、クラスタの名前は自由に変更してください（私は 'racer' と呼んでいます）。以下のコードは自分のクラスタへの参照を取得しようとしますが、存在しない場合は作成します。クラスタを作成する場合、少し時間がかかります。また、予想外の課金をされないように、実験が完了したらクラスターをオフにしてください（実際には、min_node を 0 に設定して、長時間アイドル状態になるとクラスタが自動的にオフになる設定を検討してください）。 \n\n**訳注** Azure の無償評価版などの GPU 最適化済みマシンを利用できない場合、またはコストを抑えたい場合は、vm_size を \"STANDARD_D2_V2\" にしてください。min_nodes を 1 以上にすると、訓練開始までの待ち時間を短縮できますが、コンピュートの削除し忘れなどで課金が継続されることがあるので注意してください。min_nodes を 0 にすると実行が終わると自動的にノードが削除されて課金されなくなります。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cluster = 'racer'\ntry:\n    compute = ComputeTarget(workspace=ws, name=cluster)\n    print('Found existing compute target \"{}\"'.format(cluster))\nexcept ComputeTargetException:\n    print('Creating new compute target \"{}\"...'.format(cluster))\n    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', min_nodes=1, max_nodes=6)\n    compute = ComputeTarget.create(ws, cluster, compute_config)\n    compute.wait_for_completion(show_output=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 実験の時間\nコンピューティングターゲットが設定されたら、前回の小さなノートブックをリモートコンピューティング環境で実行できる単一のスクリプトにパッケージ化します。[あなたのために](train.py) train.py を作っておきました。実際、ファイルを見ると、前のノートブックから学んだものとまったく同じ概念がすべて表示されます（これはほとんどまったく同じですが、スクリプトへの受け渡しを容易にするために追加の事項を入れています）。\n\nAzure ML サービスには実験という概念があります。実験ごとに複数回実行することができます。ここでは、実験の実行方法を定義する Estimator オブジェクトを使用しています。\n\n### バックグラウンドで何をしてるか気にしないのであれば、ここは読む必要はありません\nバックグラウンドでは、Estimator は基本的に実験を格納する docker イメージの定義です。このすべてについての最もよい部分は、あなたがあなたの実験に使うもの（TensorFlowのカスタムバージョンであっても他の何かであっても）に関係なく、それが必ず実行可能であるということです - 結局それはコンテナです。とても使いやすいです。\n\n### 通常の手順に戻る\nEstimator を Azure ML サービスで実行することを送信すると、現在のディレクトリの内容がコピーされ、新しいコンテナにまとめられます（それらは [.amlignore] ファイルに記述されたもの以外、全部アップロードされます）\n\nまた、'argparse' を使用しているので、推論器の定義の一部としてトレーニングスクリプトに外部パラメータを指定できます。\n\n次の3個のセルを実行して、何が起こるのか見てみましょう。\n\n**訳注** クラウドコンピュートを作成した際に vm_size を \"STANDARD_D2_V2\" など（GPU無し）にした場合は、下のセルで \"use_gpu=True\" を \"use_gpu=False\" に変更してください。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 実験を作成\nmnist = Experiment(ws, 'pytorchmnist')\n\n# script parameters\nscript_params={\n    '--epochs': 5,\n    '--batch': 100,\n    '--lr': .001,\n    '--model': 'cnn'\n}\n\n# Estimator を作成\nestimator = PyTorch(source_directory='.',\n                       compute_target=compute, \n                       entry_script='train.py',\n                       script_params=script_params,\n                       use_gpu=True)\n\nrun = mnist.submit(estimator)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "RunDetails(run).show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "すべて完了すると、次のようになります:\n\n![AzureML Run](https://raw.githubusercontent.com/sethjuarez/pytorchintro/master/images/run_widget.png)\n\n実際に、損失関数は時間の経過とともに（平均して）減少し、モデルの精度が上がることに注意してください。learning_rate パラメータを変更して試してみてください。詳しくは、[Azure Machine Learning service でモデルのハイパーパラメーターを調整する](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters) を参照してください。\n\nさて、どのようにしてこれらの素晴らしいチャートが表示できたのか疑問に思うかもしれません。これは Azure ML サービスが、実験結果に対して実用的な価値を付加してくれるところです。[いくつか](https://github.com/sethjuarez/pytorchintro/blob/master/train.py#L156-L166) の [戦略的](https://github.com/sethjuarez/pytorchintro/blob/master/train.py#L121-L122) に [配置](https://github.com/sethjuarez/pytorchintro/blob/master/train.py#L142-L143) されたログステートメントを使用して、Azure ML サービスはこの出力を作成しました。実際、値が複数回ログに記録されると、テーブル内の項目ではなくチャートが自動的に作成されます。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# モデル\nトレーニングがすべて完了して出力が完了したら、実際に特定の実験のすべての実行の出力を確認し、それを「公式な」ワークスペースモデルに昇格させることができます。重要なファイル（つまり私たちをお金持ちにしてくれるかもしれないモデル）が通常 Jeff という名前のコンピュータ上に置かれるのは素晴らしい機能です。現在は、多くの人がモデルのバージョン管理さえしていませんが、以下のコードを実行してください。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run.get_file_names()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model_file = 'outputs/model.pth'\nrun.download_file(name=model_file, output_file_path='model.pth')\nmodel = Model.register(ws, model_name='PyTorchMNIST', model_path='model.pth', \n                       description='CNN PyTorch Model')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# イメージ\nモデルが完成したので、それをプロダクションで使用する場合は、モデルの使用方法を定義する必要があります。これはスコアリングまたは推論とも呼ばれます。Azure ML サービスでは、基本的に2つのメソッドが必要です:\n1. `init()`\n2. `run(raw)` - JSON 文字列を取り込んで予測を返す\n\n最初にスコアリングスクリプトが実行される環境を記述し、それを設定ファイルにまとめる必要があります。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "myenv = CondaDependencies()\nmyenv.add_pip_package('numpy')\nmyenv.add_pip_package('torch')\nwith open('pytorchmnist.yml','w') as f:\n    print('Writing out {}'.format('pytorchmnist.yml'))\n    f.write(myenv.serialize_to_string())\n    print('Done!')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "次に、Azure ML サービスにスコアリングスクリプトの場所を通知する必要があります。score.py を [あらかじめ作っておきました](score.py)。ファイルを見ると、init() メソッドと run(raw) メソッドの両方が簡単に見つかるはずです。ファイルをローカルで実行して、正しい動作をしていることを確認することもできます。\n\nこれですべてが完成したので、イメージを作成しましょう。\n\n### バックグラウンドで何をしてるか気にしないのであれば、ここは読む必要はありません\n基本的には、定義からdockerイメージを作成して、Workspace に表示される Azure Container Registry にプッシュします。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**注** しばらく時間がかかります"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.image import ContainerImage, Image\n\n# イメージの作成\nimage_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n                                runtime=\"python\", \n                                conda_file=\"pytorchmnist.yml\")\n\nimage = Image.create(ws, 'pytorchmnist', [model], image_config)\nimage.wait_for_creation(show_output=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# デプロイ\nイメージ作成をせずに、残りの展開プロセスを Azure Pipelines のようなものに移動したいかもしれません。そうではなくて、このサービスを引き続きワークスペースにデプロイしたい場合は、以下を使用してください。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import Webservice, AciWebservice\n\nservice_name = 'pytorchmnist-svc'\n\n# check for existing service\nsvcs = [svc for svc in Webservice.list(ws) if svc.name==service_name]\nif len(svcs) == 1:\n    print('Deleting prior {} deployment'.format(service_name))\n    svcs[0].delete()\n\n# create service\naciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                                            memory_gb=1, \n                                            description='simple MNIST digit detection')\nservice = Webservice.deploy_from_image(workspace=ws, \n                                    image=image, \n                                    name=service_name, \n                                    deployment_config=aciconfig)\nservice.wait_for_deployment(show_output=True)\nprint(service.scoring_uri)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "イメージを ACI またはワークスペース Kubernetes クラスターにプッシュすることもできます。\n\n時々うまくいかないことがあります・・・もし実行時にそうなったら、実際の [logs](deploy.log) を見てください。!"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "with open('deploy.log','w') as f:\n    f.write(service.get_logs())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# サービスの実行\n以上でサービスは動作しています。適切に動作しているか見てみましょう。前から使っているテストデータをロードしてランダムな数字で試すことができます。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "digits = datasets.MNIST('data', train=False, download=True,\n                        transform=transforms.Compose([\n                            transforms.ToTensor(),\n                            transforms.Lambda(lambda x: x.reshape(28*28))\n                        ])\n                     )\nprint(len(digits))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "インデックスとして基本的に最大60,000まで任意の数を選ぶことができます。サービスがどのように動作しているかを見るために何回か試してみてください。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import torch\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nX, Y = digits[20]\nX = X * 255\nplt.imshow(255 - X.reshape(28,28), cmap='gray')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ポストしようとしているエンドポイントの場所\nimage_str = ','.join(map(str, X.int().tolist()))\nprint(image_str)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import json\nimport requests\nservice_url = service.scoring_uri\nprint(service_url)\nr = requests.post(service_url, json={'image': image_str })\nr.json()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 最後に\nこの小さな旅が参考になっていればうれしいです！ 私の目標は、機械学習の基本がそれほど悪いものではないと理解してもらうことです。コメント、提案、または分からないところは一言教えてください。"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
